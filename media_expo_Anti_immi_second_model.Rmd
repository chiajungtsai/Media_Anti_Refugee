---
title: "media_expo_Anti_immi_second_model (Amount_of_media_coverage)"
author: "Chia-Jung Tsai"
date: "9 5 2021"
output:
  html_document: default
  pdf_document: default
---
# Data introduction

## individual level outcome 

- logitidinal data across 2010-2017 and 16 German states (SOEP data) 

- Plj0046: Do you concern the immigration to Germany?
 (1=very concerned, 2= somewhat concerned, 3= not concerned at all)


## Macro level predictors 
### Change of demographics in each state : German official data

- Frn_rate: Rate of Foreigner  
(e.g. (N of Foreigners in Berlin in 2010)/(Total Population in Berlin in 2010)

- Asl_rate: Rate of Asylum applications in each state by year 2010-2017
 (e.g. (N of Asylum applications in Berlin in 2010)/(Total Population in Berlin in 2010)

- Log_Asylum_rate: log number of Asl_rate

- Frn_log: log Number of Foreigners in each state by year 2010-2017 (e.g. log N of Foreigners in Berlin in 2010) 
- Asl_log: log Number of Asylum applications in each state by year 2010-2017 (e.g. log N of Asylum applications in Berlin in 2010)



### media exposure (calculated via Gdelt Event database) 

- Gdelt Event database (1979-2020)  

- 1 row = 1 event

- Select Events mainly by CAMEO Event code (e.g. CAMEO 0233 "Appeal for humanitarian aid" : Make an appeal for, request, or suggest humanitarian assistance. Note: Requests for or suggestions of food, medicine, and related personnel, as well as shelter and protection, are all coded as 0233. Calls by refugees to be let into the territories of other countries (which should be coded as targets) and asylum requests all fit here. Example: Oxfam Canada today called on the world community to help save tens of thousands of Afghan civilians threatened with starvation. )

- All CAMEO codes used here are: 0233, 030, 0333,0343, 075, 0833, 1033, 1223, 1424,1623, 1663, 180, 1822, 184, and 201.
Besides, events with "REF" (refugee) code in columns 'Actor1Code' and 'Actor2Code' are also included in the data. 

- "NumArticles" and "AvgTone: In this Event data format, there are two columns "NumArticles" and "AvgTone," which refer the number and the average sentiment all the news articles regarding this event. We aggregate these 2 columns by year ("month" is also available to be used).We aggregate these 2 columns by year ("month" is also available to be used).

- Date : After 2013, data collection date ("DATEADDED") is treated as date of the event news (Gdelt collects data every 15 mins) 
Before 2013, we use the information of the file name (e.g. 20210828.export.CSV.zip ) to recognise the data. The dataset we have so far includes year and month  

- Geo-location: select by columns 'Actor1Geo_FullName', 'Actor2Geo_FullName' and 'ActionGeo_FullName' for the information 'country', 'state', and 'city.' 


- ave_artcl: the average amount of articles relating with refugees in a year (e.g.average of total amount of Jan to Dec in 2010) 
- ave_tone: the average sentiments of articles relating with refugees in a year (e.g.average of average sentiment of Jan to Dec in 2010)

#### Amount_of_media_coverage= (N of Refugee Articles per year per state)/(N of all Articles per year per state), 
#### Tone= (average sentiment of Refugee Articles per year per state)-(average sentiment of all Articles per year per state)

## others 

- Land: German states (16 states) syear: survey year (2010-2017) 

### model set up:  
- concerns of immigrants= Rate of Asylum seekers*Media exposure (Amount_of_media_coverage)

### Theory: Politicize place assumption (Daniel Hopkins, 2010) people perceive the demographic changes in the surrounding area when the media coverage interacts with it 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggplot2)
library(lme4)
library(pscl)
library(jtools)
library(haven)
library(plm)
library(gplots)
library(sjPlot)
library(sjmisc)

options(scipen = 999)

```

# Media data 
## create Amount_of_media_coverage and Tone
```{r}

load("U:/Gdelt/Gdelt/all_GM.rda")
load("U:/Gdelt/Gdelt/ref_GM.rda")

all_GM<- all_GM %>% mutate(GE_state=recode(GE_state,"Baden-WÃ¼berg"="Baden-Württemberg", 
                       "ThÃ¼n"="Thüringen"))
ref_GM <- ref_GM %>% mutate(GE_state=recode(GE_state,"Baden-WÃ¼berg"="Baden-Württemberg", 
                                           "ThÃ¼n"="Thüringen"))

A<- all_GM %>% 
  filter(Pub_Year>=2010 & Pub_Year<=2017)%>%
  group_by(Pub_Year,GE_state) %>%
  summarise(Artl=sum(NumArticles), AvgTone=mean(AvgTone))%>%
  ungroup()

B<- ref_GM %>% 
  filter(Pub_Year>=2010&Pub_Year<=2017)%>%
  group_by(Pub_Year,GE_state) %>%
  summarise(Artl=sum(NumArticles), AvgTone=mean(AvgTone))%>%
  ungroup()

Media <-A%>% 
  full_join(B, by=c("Pub_Year","GE_state")) %>%
  rename(Artl_all=Artl.x, AvgTone_all=AvgTone.x, Artl_ref=Artl.y, AvgTone_ref=AvgTone.y)

Media<-Media %>% filter(GE_state!="Germany (general)")%>%
  drop_na(GE_state)

Media <-Media %>% mutate(Artl=Artl_ref/Artl_all, Tone=AvgTone_ref-AvgTone_all) 

```
```{r}
plot(density(log(Media$Artl)))
plot(density(Media$Tone))

```

```{r}

ggplot(na.omit(Media), aes(x = Pub_Year, y = Artl, group= GE_state, colour=GE_state)) +
  geom_point() +geom_line()+ ggtitle("Average number of articles by German states")+ylim(c(0,0.06))

ggplot(na.omit(Media), aes(x = Pub_Year, y = Tone, group= GE_state, colour=GE_state)) +
  geom_point() +geom_line()+ ggtitle("Average tone of articles by German states")

```
  
## trend of number of refugee Artlcles over time by states
```{r}
library(geofacet)
ggplot2::ggplot(data=Media,aes(x=Pub_Year, y=Artl, group=1))+
  theme(axis.text.x=element_text(angle=90))+
  geom_line()+
  facet_geo(~GE_state, grid="de_states_grid1")

```
  
## trend of tone of refegee Artlcles over time by states
```{r}

ggplot2::ggplot(data=Media,aes(x=Pub_Year, y=Tone+3, group=1))+
  theme(axis.text.x=element_text(angle=90))+
  geom_line()+
  facet_geo(~GE_state, grid="de_states_grid1", label = "name")

```

```{r}
load("U:/Soep/dt.rda")
load("U:/Soep/Land_year_longformat.rda")

dt_1<- merge(dt,Land_year_longformat,by.x=c("syear","Land"),by.y = c("Year","Land"))
dt_1 <- merge(dt_1, Media, by.x=c("syear","Land"), by.y = c("Pub_Year","GE_state"))
dt_1<- dt_1 %>% select(hid, pid, syear, Land, plj0046, wrimm, 
                       Asl, Frn, Ppl, Asl_rate, Frn_rate, 
                       Asl_log, Frn_log, Ppl_log, 
                       Artl, Tone) 
dt_1<- dt_1 %>% drop_na() %>% mutate(logASLr=log(Asl_rate)) %>% rename(year=syear)
```

# Random intercept model
```{r}

#for revising the figure
dt_n <- dt_1 %>% rename (Log_Asylum_rate=logASLr,Amount_of_media_coverage=Artl)

# random intercept
logit_ri<-glmer(wrimm ~ 1+Log_Asylum_rate*Amount_of_media_coverage + factor(year) +(1|Land), 
                data=dt_n, family=binomial(link = "logit"), 
                control= glmerControl(optimizer="bobyqa"),nAGQ =0)
summary(logit_ri)

lattice::dotplot(ranef(logit_ri, which="Land", conVar=TRUE), scale= list(y=list(cex=0.5)))
exp(coef(logit_ri)$Land)

```
## Prediction for random intercept
```{r}
# table for random intercept

tab_model(logit_ri)

```

```{r}

# Extract out the fixed-effect slope for Year2
slope <- fixef(logit_ri)['Log_Asylum_rate:Amount_of_media_coverage']

# Extract out the random-effect slopes for county
Land_intercept <- ranef(logit_ri)$Land

# Create a new column for the slope
Land_intercept$slope <- slope

# Use the row names to create a county name column
Land_intercept$Land <- rownames(Land_intercept)
colnames(Land_intercept)[1]<- "intercept"



ggplot(data=Land_intercept)+
  geom_abline(aes(slope=slope,intercept=intercept,color=Land))+
  theme_minimal()+
  xlim(c(0,2))+ylim(c(-3,3))+
  scale_colour_discrete(breaks=unique(Land_intercept$Land[order(Land_intercept$intercept, decreasing = TRUE)]))


```  
  
## marginal effects
```{r}
# marginal effects of year
library(ggeffects)
pd_yr<- ggpredict(logit_ri,term="year")
plot(pd_yr)+ylim(c(0,0.45))

```

```{r}
# marginal effects of log Asylum rate/ Article
pd_Log_Asylum_rate<- ggpredict(logit_ri,term="Log_Asylum_rate[all]")
plot(pd_Log_Asylum_rate)+ylim(c(0,0.4))

pd_Amount_of_media_coverage<- ggpredict(logit_ri,term="Amount_of_media_coverage [all]")
plot(pd_Amount_of_media_coverage)+ylim(c(0,0.4))

```
```{r}
ggpredict(logit_ri,term=c("Log_Asylum_rate[all]","Amount_of_media_coverage")) %>% plot()

```
  
# model checking and diagnostics for random intercept model (not so sure)
```{r}
# model checking and diagnostics for random intercept

# linearity of x (residual plot of x)
ggplot(data.frame(x1=dt_n$Log_Asylum_rate,pearson=residuals(logit_ri,type="pearson")),
      aes(x=x1,y=pearson)) +
    geom_point() +
    theme_bw()

ggplot(data.frame(x2=dt_n$Amount_of_media_coverage,pearson=residuals(logit_ri,type="pearson")),
      aes(x=x2,y=pearson)) +
    geom_point() +
    theme_bw()


```
```{r}
# Independence (if the x1 x2 correlate with group1) :  Log_Asylum_rate correlates with group effect (fixed effect may be biased)

means <- aggregate(dt_n[,c("Log_Asylum_rate","Amount_of_media_coverage")],by=list(dt_n$Land),FUN=mean)
glmcoefs <- summary(glm(wrimm ~ Log_Asylum_rate + Amount_of_media_coverage + Land, data=dt_n))$coefficients[,"Estimate"]
means$effects <- c(0,glmcoefs[substr(names(glmcoefs),1,4) == "Land"])
means$effects <- means$effects - mean(means$effects)

cor(means[,c("Log_Asylum_rate","Amount_of_media_coverage","effects")])

ggplot(means, aes(x=Log_Asylum_rate,y=effects)) +
    geom_point() +
    theme_bw()

ggplot(means, aes(x=Amount_of_media_coverage,y=effects)) +
    geom_point() +
    theme_bw()

fixef(logit_ri)
glmcoefs[1:3]

```
```{r}

# level 1 QQ plot (to check normality)
qqnorm(residuals(logit_ri))
qqline(residuals(logit_ri))

hist(residuals(logit_ri)) 



# level 2 QQ plot (to check normality) : does not work 
# stats::qqnorm(logit_ri, ~ranef(.)) 
# qqnorm(logit_ri, ~ resid(., type = "p") | year, abline = c(0, 1))

```
```{r}
# Sensitivity to data (check that your model is not influenced by one or a small set of observations)

ggplot(data.frame(lev=hatvalues(logit_ri),pearson=residuals(logit_ri,type="pearson")),
      aes(x=lev,y=pearson)) +
    geom_point() +
    theme_bw()


```

  
# Random slope model with constrained intercept

```{r}
# random slope with constrained intercept

logit_rsci<-glmer(wrimm ~ 1+Log_Asylum_rate*Amount_of_media_coverage + factor(year) +(Log_Asylum_rate*Amount_of_media_coverage-1|Land), data=dt_n, family=binomial(link = "logit"), 
                control= glmerControl(optimizer="bobyqa"),nAGQ =0)
summary(logit_rsci)

exp(coef(logit_rsci)$Land)

re_rsci<-ranef(logit_rsci, which="Land", conVar=TRUE)
names(re_rsci)<-"Figure 3:The effect of asylum application rate and media salience across regions"
lattice::dotplot(re_rsci, scales = list(x =list(relation = 'free')))


```
  
## Prediction for random slope with constrained intercept
```{r}
# table for random intercept

tab_model(logit_rsci)

```

```{r}

# Extract out the fixed-effect slope for our main effect
slope_rsci <- rep(fixef(logit_rsci)['Log_Asylum_rate:Amount_of_media_coverage'],16)

# Extract out the random-effect slopes for Land
Land_rsci <- ranef(logit_rsci)$Land

# Create a new column for the slope
Land_rsci$slope <- Land_rsci$`Log_Asylum_rate:Amount_of_media_coverage` + slope_rsci

# Use the row names to create a Land name column
Land_rsci$Land <- rownames(Land_rsci)
Land_rsci$intercept <- fixef(logit_rsci)['(Intercept)']

ggplot(data=Land_rsci)+
  geom_abline(aes(slope=slope,intercept=intercept,color=Land))+
  theme_minimal()+
  xlim(c(0,2))+ylim(c(-3,3))+
  scale_colour_discrete(breaks=unique(Land_rsci$Land[order(Land_rsci$slope, decreasing = TRUE)]))


```
  
## marginal effects
```{r}
# marginal effects of year
library(ggeffects)
pd_yr_rsci<- ggpredict(logit_rsci,term="year")
plot(pd_yr_rsci)+ylim(c(0,0.5))

```

```{r}
# marginal effects of log Asylum rate/ Article
pd_ASLr_rsci<- ggpredict(logit_rsci,term="Log_Asylum_rate[all]")
plot(pd_ASLr_rsci)+ylim(c(0,0.4))

pd_Artl_rsci<- ggpredict(logit_rsci,term="Amount_of_media_coverage [all]")
plot(pd_Artl_rsci)+ylim(c(0,0.4))

```

```{r}

ggpredict(logit_rsci,term=c("Log_Asylum_rate [all]","Amount_of_media_coverage")) %>% plot()

ggpredict(logit_rsci,term=c("Log_Asylum_rate [all]","Amount_of_media_coverage"),type = "re") %>% plot()

```
  
## model checking and diagnostics for random slope with constrained intercept (not so sure)
```{r}
# model checking and diagnostics for random slope with constrained intercept
# linearity of x (residual plot of x)
ggplot(data.frame(x1=dt_n$Log_Asylum_rate,pearson=residuals(logit_rsci,type="pearson")),
      aes(x=x1,y=pearson)) +
    geom_point() +
    theme_bw()

ggplot(data.frame(x2=dt_n$Amount_of_media_coverage,pearson=residuals(logit_rsci,type="pearson")),
      aes(x=x2,y=pearson)) +
    geom_point() +
    theme_bw()


```

```{r}
# Independence (if the x1 x2 correlate with group1) :  Log_Asylum_rate correlates with group effect (fixed effect may be a bit biased)

means_rsci <- aggregate(dt_n[,c("Log_Asylum_rate","Amount_of_media_coverage")],by=list(dt_n$Land),FUN=mean)
glmcoefs_rsci <- summary(glm(wrimm ~ Log_Asylum_rate + Amount_of_media_coverage + Land, data=dt_n))$coefficients[,"Estimate"]
means_rsci$effects <- c(0,glmcoefs_rsci[substr(names(glmcoefs_rsci),1,4) == "Land"])
means_rsci$effects <- means_rsci$effects - mean(means_rsci$effects)

cor(means_rsci[,c("Log_Asylum_rate","Amount_of_media_coverage","effects")])

ggplot(means_rsci, aes(x=Log_Asylum_rate,y=effects)) +
    geom_point() +
    theme_bw()

ggplot(means_rsci, aes(x=Amount_of_media_coverage,y=effects)) +
    geom_point() +
    theme_bw()

fixef(logit_rsci)
glmcoefs_rsci[1:3]

```

```{r}

# level 1 QQ plot (to check normality)
qqnorm(residuals(logit_rsci))
qqline(residuals(logit_rsci))

hist(residuals(logit_rsci)) 

# level 2 QQ plot (to check normality) : does not work 
# stats::qqnorm(logit_rsci, ~ranef(.)) 
# qqnorm(logit_rsci, ~ resid(., type = "p") | year, abline = c(0, 1))


```
```{r}
# Sensitivity to data (check that your model is not influenced by one or a small set of observations)

ggplot(data.frame(lev=hatvalues(logit_rsci),pearson=residuals(logit_rsci,type="pearson")),
      aes(x=lev,y=pearson)) +
    geom_point() +
    theme_bw()


```
   
# random slope model (with random intercept as well as random slope)

```{r}
# random slope 


logit_rs<-glmer(wrimm ~ 1+Log_Asylum_rate*Amount_of_media_coverage + factor(year) +(Log_Asylum_rate*Amount_of_media_coverage|Land), data=dt_n, family=binomial(link = "logit"), 
                control= glmerControl(optimizer="bobyqa"),nAGQ =0)
summary(logit_rs)

exp(coef(logit_rs)$Land)

re_rs<-ranef(logit_rs, which="Land", conVar=TRUE)
names(re_rs)<-"Figure 3:The effect of asylum application rate and media salience across regions"
lattice::dotplot(re_rs, scales = list(x =list(relation = 'free')))


```
  
## Prediction for random slope model
```{r}
# table for random intercept

tab_model(logit_rs)

```



```{r}

# Extract out the fixed-effect slope for our main effect
slope_rs <- rep(fixef(logit_rs)['Log_Asylum_rate:Amount_of_media_coverage'],16)

# Extract out the random-effect slopes for Land
Land_rs <- ranef(logit_rs)$Land

# Create a new column for the slope
Land_rs$slope <- Land_rs$`Log_Asylum_rate:Amount_of_media_coverage` + slope_rs

# Use the row names to create a Land name column
Land_rs$Land <- rownames(Land_rs)
names(Land_rs)[1] <- "intercept"



ggplot(data=Land_rs)+
  geom_abline(aes(slope=slope,intercept=intercept,color=Land))+
  theme_minimal()+
  xlim(c(0,2))+ylim(c(-3,3))+
  scale_colour_discrete(breaks=unique(Land_rsci$Land[order(Land_rs$slope, decreasing = TRUE)]))


```

## marginal effects of the random slope model
```{r}
# marginal effects of year
pd_yr_rs<- ggpredict(logit_rs,term="year")
plot(pd_yr_rs)+ylim(c(0,0.5))

```

```{r}
# marginal effects of log Asylum rate/ Article
pd_ASLr_rs<- ggpredict(logit_rs,term="Log_Asylum_rate[all]")
plot(pd_ASLr_rs)+ylim(c(0,0.4))

pd_Artl_rs<- ggpredict(logit_rs,term="Amount_of_media_coverage [all]")
plot(pd_Artl_rs)+ylim(c(0,0.4))

```

```{r}
ggpredict(logit_rs,term=c("Log_Asylum_rate [all]","Amount_of_media_coverage")) %>% plot()

```
  
## model checking and diagnostics for random slope model (not so sure)
```{r}
# model checking and diagnostics for random slope 
# linearity of x (residual plot of x)
ggplot(data.frame(x1=dt_n$Log_Asylum_rate,pearson=residuals(logit_rs,type="pearson")),
      aes(x=x1,y=pearson)) +
    geom_point() +
    theme_bw()

ggplot(data.frame(x2=dt_n$Amount_of_media_coverage,pearson=residuals(logit_rs,type="pearson")),
      aes(x=x2,y=pearson)) +
    geom_point() +
    theme_bw()


```

```{r}
# Independence (if the x1 x2 correlate with group1) :  Log_Asylum_rate correlates with group effect (fixed effect may be a bit biased)

means_rs <- aggregate(dt_n[,c("Log_Asylum_rate","Amount_of_media_coverage")],by=list(dt_n$Land),FUN=mean)
glmcoefs_rs <- summary(glm(wrimm ~ Log_Asylum_rate + Amount_of_media_coverage + Land, data=dt_n))$coefficients[,"Estimate"]
means_rs$effects <- c(0,glmcoefs_rs[substr(names(glmcoefs_rs),1,4) == "Land"])
means_rs$effects <- means_rs$effects - mean(means_rs$effects)

cor(means_rs[,c("Log_Asylum_rate","Amount_of_media_coverage","effects")])

ggplot(means_rs, aes(x=Log_Asylum_rate,y=effects)) +
    geom_point() +
    theme_bw()

ggplot(means_rs, aes(x=Amount_of_media_coverage,y=effects)) +
    geom_point() +
    theme_bw()

fixef(logit_rs)
glmcoefs_rs[1:3]

```

```{r}

# level 1 QQ plot (to check normality)
qqnorm(residuals(logit_rs))
qqline(residuals(logit_rs))

hist(residuals(logit_rs)) 

# level 2 QQ plot (to check normality) : does not work 
# stats::qqnorm(logit_rs, ~ranef(.)) 
# qqnorm(logit_rs, ~ resid(., type = "p") | year, abline = c(0, 1))


```

```{r}
# Sensitivity to data (check that your model is not influenced by one or a small set of observations)

ggplot(data.frame(lev=hatvalues(logit_rs),pearson=residuals(logit_rsci,type="pearson")),
      aes(x=lev,y=pearson)) +
    geom_point() +
    theme_bw()


```

# Compare Random intercept, Ramdon slope with constrained intercept, Random slope

```{r}
# anova test
anova(logit_ri,logit_rsci,logit_rs)

```
  
# Effect size 
### Note : effect size/ R^2 remains problematic
```{r} 
# effect size (The approach of Jarrett Byrnes): the correlation between the fitted and the observed values, which could be seen as general R^2
r2.corr.mer <- function(m) {
  lmfit <-  lm(model.response(model.frame(m)) ~ fitted(m))
  summary(lmfit)$r.squared
}

#Then apply the function on the different models
r2.corr.mer(logit_ri)
r2.corr.mer(logit_rsci)
r2.corr.mer(logit_rs)


```
```{r}
# piecewiseSEM is a package developed by Jarrett Byrnes
# piecewiseSEM::rsquared(logit_ri)
# piecewiseSEM::rsquared(logit_rsci)
# piecewiseSEM::rsquared(logit_rs)
```
  
#### For mixed-effects models, R_GLMM² comes in two types: marginal and conditional. 
Marginal R_GLMM² represents the variance explained by the fixed effects, and is defined as: 
R_GLMM(m)² = (σ_f²) / (σ_f² + σ_α² + σ_ε²) 

Conditional R_GLMM² is interpreted as a variance explained by the entire model, including both fixed and random effects, and is calculated according to the equation: 

R_GLMM(c)² = (σ_f² + σ_α²) / (σ_f² + σ_α² + σ_ε²) 

where σ_f² is the variance of the fixed effect components, σ_α² is the variance of the random effects, and σ_ε² is the “observation-level” variance. 

Three different methods are available for deriving the observation-level variance σ_\varepsilon: the delta method, lognormal approximation and using the trigamma function. The delta method can be used with for all distributions and link functions, while lognormal approximation and trigamma function are limited to distributions with logarithmic link. Trigamma-estimate is recommended whenever available. Additionally, for binomial distributions, theoretical variances exist specific for each link function distribution.  
Source: https://rdrr.io/cran/MuMIn/man/r.squaredGLMM.html


#### source of formular: https://stackoverflow.com/questions/67586900/how-can-i-calculate-the-marginal-r2-for-linear-mixed-models-in-spss-for-a-simpl  
####### An important discussion! But remain unsolved!   


#### clculate R^2m and R^m manually
##### Vf (fixed effect variance), Vr (random effect variance), Ve (residual variance)  

> the residual variance (Ve) should be (π^2)/3 for generalized linear mixed models with binomial data and logit link function (Nakagawa, S., Schielzeth, H. 2010. Repeatability for Gaussian and non-Gaussian data: a practical guide for biologists. Biol. Rev. 85:935-956.).  
Source: https://stats.stackexchange.com/questions/128750/residual-variance-for-glmer 


```{r}
Vf<- var(predict(logit_ri,re.form=NA))
Vr <- insight::get_variance_random(logit_ri) 
Ve <- (pi^2)/3  # or sigma(logit_ri)^2  # or using attr(VarCorr(logit_ri),"sc")  # all 3 models are equal to 1 (WHY? )

R2m_ri <- Vf / (Vf + Vr + Ve)
R2m_ri
R2c_ri <- (Vf + Vr) / (Vf + Vr + Ve)
R2c_ri

```

```{r}
Vf<- var(predict(logit_rsci,re.form=NA))
Vr <-  21.925834 
Ve <- (pi^2)/3

R2m_rsci <- Vf / (Vf + Vr + Ve)
R2m_rsci
R2c_rsci <- (Vf + Vr) / (Vf + Vr + Ve)
R2c_rsci

```

```{r}
Vf<- var(predict(logit_rs,re.form=NA))
Vr <- 1.371361 + 0.354988
Ve <- (pi^2)/3

R2m_rs <- Vf / (Vf + Vr + Ve)
R2m_rs
R2c_rs <- (Vf + Vr) / (Vf + Vr + Ve)
R2c_rs

```

## ICC (remain unsolved)
- a measure of how much of the variation in the response variable, which is not attributed to fixed effects, is accounted for by a random effect. It is the ratio of the variance of the random effect to the total random variation. 
- For the generalized model, the residual variance is a known constant. We will use (15/16) 2 π 2 /3 (15/16)2π2/3 as an estimate of the variance of the logistic distribution. 

```{r}
# ICC for random intercept (for ramdom slope... there's some problems)
r1Var <- as.numeric(VarCorr(logit_ri)[["Land"]])
residVar <- (15/16)^2 * pi^2 / 3
r1Var
residVar
r1Var / (r1Var + residVar)

```











